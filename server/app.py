# -*- coding: utf-8 -*-
"""
åº”ç”¨è£…é…å…¥å£ï¼ˆè“å›¾ä¼˜å…ˆï¼‰
- åˆ›å»ºå…¨æ–° Flask åº”ç”¨å¹¶æ³¨å†Œè“å›¾ä¸é™æ€è·¯ç”±
- å¤ç”¨ api_server_qwen3vl çš„å…¨å±€å¯¹è±¡/ç›®å½•/é€»è¾‘ï¼Œä½†ä¸å¤ç”¨å…¶ä¸­çš„ app
"""
from flask import Flask, send_from_directory
# from flask_cors import CORS  # ä¸´æ—¶æ³¨é‡Šæ‰ï¼Œç½‘ç»œé—®é¢˜æ— æ³•å®‰è£…
import os
import yaml

# âš ï¸ å…³é”®ï¼šåœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®CUDA_VISIBLE_DEVICES
# å…ˆåŠ è½½é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è®¾ç½®CUDA_VISIBLE_DEVICES
try:
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, "config_qwen3vl.yaml")
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            early_config = yaml.safe_load(f)
        device_config = early_config.get("model", {}).get("device", "cuda:0")
        if isinstance(device_config, list):
            # å¤šGPUé…ç½®ï¼Œæå–GPUç´¢å¼•å¹¶è®¾ç½®CUDA_VISIBLE_DEVICES
            gpu_indices = []
            for device in device_config:
                if device.startswith("cuda:"):
                    try:
                        gpu_idx = int(device.split(":")[1])
                        gpu_indices.append(str(gpu_idx))
                    except (ValueError, IndexError):
                        pass
            if gpu_indices:
                cuda_visible_devices = ",".join(gpu_indices)
                os.environ["CUDA_VISIBLE_DEVICES"] = cuda_visible_devices
                print(f"ğŸ”§ åœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®CUDA_VISIBLE_DEVICES={cuda_visible_devices}ï¼ˆå¯¹åº”å®é™…GPU {device_config}ï¼‰")
        elif isinstance(device_config, str) and device_config.startswith("cuda:"):
            # å•GPUé…ç½®ï¼Œä¹Ÿéœ€è¦è®¾ç½®CUDA_VISIBLE_DEVICES
            try:
                gpu_idx = int(device_config.split(":")[1])
                os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_idx)
                print(f"ğŸ”§ åœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®CUDA_VISIBLE_DEVICES={gpu_idx}ï¼ˆå¯¹åº”å®é™…GPU {device_config}ï¼‰")
            except (ValueError, IndexError):
                print(f"âš ï¸ æ— æ³•è§£æå•GPUé…ç½®: {device_config}")
except Exception as e:
    print(f"âš ï¸ é¢„åŠ è½½é…ç½®å¤±è´¥ï¼Œå°†åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶è®¾ç½®CUDA_VISIBLE_DEVICES: {e}")

try:
    # æ”¯æŒä»¥åŒ…æ–¹å¼è¿è¡Œï¼špython -m server.app
    from . import api_server_qwen3vl as api
    from .routes.health import bp_health
    from .routes.chat import bp_chat
    from .routes.upload import bp_upload
    from .routes.training import bp_training
except Exception:
    # æ”¯æŒç›´æ¥è„šæœ¬è¿è¡Œï¼špython server/app.py
    import sys
    import os as _os
    sys.path.append(_os.path.dirname(_os.path.dirname(_os.path.abspath(__file__))))
    import api_server_qwen3vl as api
    from routes.health import bp_health
    from routes.chat import bp_chat
    from routes.upload import bp_upload
    from routes.training import bp_training
finally:
    # ç»Ÿä¸€æ¨¡å—å®ä¾‹ï¼Œé¿å…åŒæ—¶å­˜åœ¨ 'api_server_qwen3vl' ä¸ 'server.api_server_qwen3vl' å¯¼è‡´çš„å…¨å±€çŠ¶æ€åˆ†è£‚
    import sys as _sys
    _sys.modules['api_server_qwen3vl'] = api
    _sys.modules['server.api_server_qwen3vl'] = api

def create_app():
    app = Flask(__name__)
    # CORS(app)  # ä¸´æ—¶æ³¨é‡Šæ‰ï¼Œç½‘ç»œé—®é¢˜æ— æ³•å®‰è£…

    # é™æ€æ–‡ä»¶è·¯ç”±ï¼Œå§”æ‰˜åˆ° api æ¨¡å—ä¸­çš„ä¸Šä¼ ç›®å½•
    @app.route("/static/images/<path:filename>")
    def serve_uploaded_image(filename: str):
        return send_from_directory(api.IMAGE_UPLOAD_DIR, filename)

    @app.route("/static/videos/<path:filename>")
    def serve_uploaded_video(filename: str):
        return send_from_directory(api.VIDEO_UPLOAD_DIR, filename)

    @app.route("/static/audios/<path:filename>")
    def serve_uploaded_audio(filename: str):
        return send_from_directory(api.AUDIO_UPLOAD_DIR, filename)

    @app.route("/static/files/<path:filename>")
    def serve_uploaded_file(filename: str):
        return send_from_directory(api.FILE_UPLOAD_DIR, filename)

    # æ³¨å†Œè“å›¾ï¼ˆçœŸå®å®ç°ï¼‰
    app.register_blueprint(bp_health)
    app.register_blueprint(bp_chat)
    app.register_blueprint(bp_upload)
    app.register_blueprint(bp_training)

    # åˆå§‹åŒ–å¿…è¦çš„é…ç½®ï¼ˆè®¾å®š server_base_urlï¼Œé¿å…ä¸‹è½½åˆ°æœ¬åœ°æ—¶URLæ‹¼æ¥å¤±è´¥ï¼‰
    try:
        api.config = api.load_config(None)
        host_for_url = api.config["server"].get("public_host") or api.config["server"].get("host", "127.0.0.1")
        if host_for_url in ("0.0.0.0", "::"):
            host_for_url = "127.0.0.1"
        api.server_base_url = f"http://{host_for_url}:{api.config['server']['port']}"
    except Exception:
        # å®‰å…¨å…œåº•
        api.server_base_url = "http://127.0.0.1:9999"

    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆä¿®å¤æœªåŠ è½½æ¨¡å‹å¯¼è‡´æ— CUDAå ç”¨çš„é—®é¢˜ï¼‰
    try:
        device = api.config.get("model", {}).get("device", "cuda:0")
        
        # ä¼˜å…ˆå°è¯•æŸ¥æ‰¾æœ€æ–°è®­ç»ƒæ¨¡å‹
        api._log.info("=" * 60)
        api._log.info("ğŸ” å¼€å§‹æŸ¥æ‰¾æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆæŸ¥æ‰¾æœ€æ–°è®­ç»ƒæ¨¡å‹ï¼‰")
        api._log.info("=" * 60)
        
        memory_config = api.config.get("memory", {}).get("training", {})
        trained_model_dir = memory_config.get("trained_model_dir", "./server/models/trained")
        token_added_model_dir = memory_config.get("token_added_model_dir", "./server/models/token_added")
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
        import os
        script_dir = os.path.dirname(os.path.abspath(__file__))  # serverç›®å½•
        project_root = os.path.dirname(script_dir)  # é¡¹ç›®æ ¹ç›®å½•
        if not os.path.isabs(trained_model_dir):
            # è·¯å¾„ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼Œç›´æ¥æ‹¼æ¥
            trained_model_dir = os.path.abspath(os.path.join(project_root, trained_model_dir))
        if not os.path.isabs(token_added_model_dir):
            token_added_model_dir = os.path.abspath(os.path.join(project_root, token_added_model_dir))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨ï¼ˆé¿å…os.listdiræŠ¥é”™ï¼‰
        os.makedirs(trained_model_dir, exist_ok=True)
        os.makedirs(token_added_model_dir, exist_ok=True)
        
        api._log.info(f"ğŸ“ è®­ç»ƒæ¨¡å‹ç›®å½•: {trained_model_dir}")
        
        model_path = None
        # æŸ¥æ‰¾æ‰€æœ‰æŒ‰æ—¶é—´æˆ³å‘½åçš„æ¨¡å‹ç›®å½•
        if os.path.exists(trained_model_dir):
            api._log.info(f"âœ… è®­ç»ƒæ¨¡å‹ç›®å½•å­˜åœ¨ï¼Œå¼€å§‹æ‰«æ...")
            model_dirs = [
                d for d in os.listdir(trained_model_dir)
                if os.path.isdir(os.path.join(trained_model_dir, d)) and d.startswith("model_")
            ]
            
            if model_dirs:
                api._log.info(f"ğŸ“Š æ‰¾åˆ° {len(model_dirs)} ä¸ªè®­ç»ƒæ¨¡å‹ç›®å½•")
                # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
                model_dirs.sort(reverse=True)
                api._log.info(f"ğŸ“‹ è®­ç»ƒæ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰:")
                for i, d in enumerate(model_dirs[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    api._log.info(f"   {i}. {d}")
                if len(model_dirs) > 5:
                    api._log.info(f"   ... è¿˜æœ‰ {len(model_dirs) - 5} ä¸ªæ¨¡å‹")
                
                latest_model = os.path.join(trained_model_dir, model_dirs[0])
                model_path = latest_model
                api._log.info("=" * 60)
                api._log.info(f"âœ… æ‰¾åˆ°æœ€æ–°è®­ç»ƒæ¨¡å‹ï¼Œå°†ä¼˜å…ˆåŠ è½½")
                api._log.info(f"ğŸ“¦ æ¨¡å‹è·¯å¾„: {model_path}")
                api._log.info(f"ğŸ“… æ¨¡å‹æ—¶é—´æˆ³: {model_dirs[0]}")
                api._log.info("=" * 60)
            else:
                api._log.warning(f"âš ï¸ è®­ç»ƒæ¨¡å‹ç›®å½•å­˜åœ¨ä½†ä¸ºç©ºï¼Œæœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒæ¨¡å‹")
        else:
            api._log.warning(f"âš ï¸ è®­ç»ƒæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {trained_model_dir}")
        
        # å¦‚æœæ²¡æœ‰è®­ç»ƒæ¨¡å‹ï¼ŒæŸ¥æ‰¾æ·»åŠ äº†tokençš„æ¨¡å‹
        if model_path is None:
            api._log.info("=" * 60)
            api._log.info("ğŸ” æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹ï¼Œæ£€æŸ¥å·²æ·»åŠ tokençš„æ¨¡å‹")
            api._log.info("=" * 60)
            api._log.info(f"ğŸ“ tokenæ¨¡å‹ç›®å½•: {token_added_model_dir}")
            if os.path.exists(token_added_model_dir):
                model_dirs = [
                    d for d in os.listdir(token_added_model_dir)
                    if os.path.isdir(os.path.join(token_added_model_dir, d)) and d.startswith("model_")
                ]
                if model_dirs:
                    model_dirs.sort(reverse=True)
                    latest_token_model = os.path.join(token_added_model_dir, model_dirs[0])
                    model_path = latest_token_model
                    api._log.info(f"âœ… æ‰¾åˆ°æ·»åŠ äº†tokençš„æ¨¡å‹: {model_path}")
                    api._log.info(f"ğŸ“… æ¨¡å‹æ—¶é—´æˆ³: {model_dirs[0]}")
                else:
                    api._log.warning("âš ï¸ tokenæ¨¡å‹ç›®å½•ä¸ºç©º")
            else:
                api._log.warning("âš ï¸ tokenæ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        if model_path is None:
            api._log.info("=" * 60)
            api._log.info("â„¹ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„åŸºç¡€æ¨¡å‹è·¯å¾„")
            api._log.info("=" * 60)
            model_path = api.config.get("model", {}).get("path")
            if model_path:
                api._log.info(f"ğŸ“¦ ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹è·¯å¾„: {model_path}")
            else:
                # å¦‚æœé…ç½®ä¸­ä¹Ÿæ²¡æœ‰ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹è·¯å¾„
                model_path = memory_config.get("base_model_path", "./models/Qwen3-VL-4B-Thinking")
                api._log.info(f"ğŸ“¦ ä½¿ç”¨é»˜è®¤åŸºç¡€æ¨¡å‹è·¯å¾„: {model_path}")
        
        api.initialize_model(model_path, device)
        api._log.info("âœ… æ¨¡å‹å·²åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        api._log.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)

    # åˆå§‹åŒ–è®­ç»ƒè°ƒåº¦å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        memory_config = api.config.get("memory", {}).get("training", {})
        training_enabled = memory_config.get("enabled", False)
        if training_enabled:
            from memory.training_scheduler import MemoryTrainingScheduler
            import sys
            script_path = os.path.abspath(__file__)
            script_args = sys.argv[1:] if hasattr(sys, 'argv') else []
            api.training_scheduler = MemoryTrainingScheduler(api.config, script_path, script_args)
            api.training_scheduler.start()
            api._log.info("âœ… è®­ç»ƒè°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œå°†åœ¨æŒ‡å®šæ—¶é—´è‡ªåŠ¨æ‰§è¡Œè®­ç»ƒ")
        else:
            api._log.info("â„¹ï¸ è®°å¿†è®­ç»ƒæœªå¯ç”¨ï¼Œè·³è¿‡è®­ç»ƒè°ƒåº¦å™¨å¯åŠ¨")
    except Exception as e:
        api._log.error(f"âŒ è®­ç»ƒè°ƒåº¦å™¨åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        # ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨ï¼Œåªæ˜¯è®°å½•é”™è¯¯

    return app

app = create_app()

__all__ = ["app", "create_app"]

if __name__ == "__main__":
    # ç»Ÿä¸€å…¥å£ï¼šç›´æ¥è¿è¡Œæœ¬æ–‡ä»¶å³å¯å¯åŠ¨ï¼ˆè“å›¾æ¨¡å¼ï¼‰
    host = api.config.get("server", {}).get("host", "0.0.0.0") if isinstance(getattr(api, "config", {}), dict) else "0.0.0.0"
    port = api.config.get("server", {}).get("port", 9999) if isinstance(getattr(api, "config", {}), dict) else 9999
    app.run(host=host, port=port, debug=False, threaded=True)
